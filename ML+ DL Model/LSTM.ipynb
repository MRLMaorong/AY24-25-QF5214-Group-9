{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU exists \n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU exists \")\n",
    "else:\n",
    "    print(\"GPU does not exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('调整后月频回归的面板数据.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 3  \n",
    "features = ['CI005001', 'CI005002',\n",
    "       'CI005003', 'CI005004', 'CI005005', 'CI005006', 'CI005007', 'CI005008',\n",
    "       'CI005009', 'CI005010', 'CI005011', 'CI005012', 'CI005013', 'CI005014',\n",
    "       'CI005015', 'CI005016', 'CI005017', 'CI005018', 'CI005019', 'CI005020',\n",
    "       'CI005021', 'CI005022', 'CI005023', 'CI005024', 'CI005025', 'CI005026',\n",
    "       'CI005027', 'CI005028', 'CI005029', 'CI005030', 'Analyst Sentiment',\n",
    "       'Beta', 'Book-to-Price', 'Dividend Yield', 'Earnings Quality',\n",
    "       'Earnings Variability', 'Earnings Yield', 'Growth', 'Industry Momentum',\n",
    "       'Investment Quality', 'Leverage', 'Liquidity', 'Long-Term Reversal',\n",
    "       'Mid Capitalization', 'Momentum', 'Profitability',\n",
    "       'Residual Volatility', 'Seasonality', 'Short-Term Reversal', 'Size'] \n",
    "target = 'next_Rtn'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426410, 3, 50) (426410,)\n",
      "(72263, 3, 50) (72263,)\n"
     ]
    }
   ],
   "source": [
    "# 设定分割线\n",
    "split_date = pd.to_datetime('2022-12-31')\n",
    "\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []\n",
    "\n",
    "for stock, group in df.groupby('S_INFO_WINDCODE'):\n",
    "    group = group.sort_values('TRADE_DT').reset_index(drop=True)\n",
    "    arr_features = group[features].values\n",
    "    arr_dates = group['TRADE_DT'].values\n",
    "    arr_target = group[target].values\n",
    "\n",
    "    for i in range(n_steps, len(group)):\n",
    "        end_date = arr_dates[i]\n",
    "\n",
    "        window_x = arr_features[i-n_steps:i, :]  \n",
    "        window_y = arr_target[i]\n",
    "\n",
    "\n",
    "        if end_date <= split_date:\n",
    "            X_train_list.append(window_x)\n",
    "            y_train_list.append(window_y)\n",
    "        else:\n",
    "            X_test_list.append(window_x)\n",
    "            y_test_list.append(window_y)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "X_test = np.array(X_test_list) \n",
    "y_test = np.array(y_test_list)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "with open('train_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, y_train), f)\n",
    "\n",
    "with open('test_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_test, y_test), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_data.pkl', 'rb') as f:\n",
    "    X_train, y_train = pickle.load(f)\n",
    "with open('test_data.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(units=hp.Int('lstm_units_1', min_value=32, max_value=128, step=32),\n",
    "                          return_sequences=True,\n",
    "                          input_shape=(n_steps, len(features))))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(layers.LSTM(units=hp.Int('lstm_units_2', min_value=32, max_value=128, step=32)))\n",
    "    model.add(layers.Dropout(rate=hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    lr = hp.Choice('learning_rate', values=[1e-4])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr,clipnorm=1.0), loss='mse', metrics=['mae'])\n",
    "    model.summary\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11993/11993 [==============================] - 175s 14ms/step - loss: 0.0192 - mae: 0.0980 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "Epoch 2/10\n",
      "11993/11993 [==============================] - 150s 13ms/step - loss: 0.0189 - mae: 0.0970 - val_loss: 0.0191 - val_mae: 0.0988\n",
      "Epoch 3/10\n",
      "11993/11993 [==============================] - 155s 13ms/step - loss: 0.0189 - mae: 0.0968 - val_loss: 0.0191 - val_mae: 0.0985\n",
      "Epoch 4/10\n",
      "11993/11993 [==============================] - 151s 13ms/step - loss: 0.0189 - mae: 0.0967 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "Epoch 5/10\n",
      "11993/11993 [==============================] - 164s 14ms/step - loss: 0.0188 - mae: 0.0967 - val_loss: 0.0191 - val_mae: 0.0983\n",
      "Epoch 6/10\n",
      "11993/11993 [==============================] - 167s 14ms/step - loss: 0.0188 - mae: 0.0966 - val_loss: 0.0191 - val_mae: 0.0989\n",
      "Epoch 7/10\n",
      "11993/11993 [==============================] - 166s 14ms/step - loss: 0.0188 - mae: 0.0965 - val_loss: 0.0191 - val_mae: 0.0983\n",
      "Epoch 8/10\n",
      "11993/11993 [==============================] - 167s 14ms/step - loss: 0.0188 - mae: 0.0965 - val_loss: 0.0191 - val_mae: 0.0986\n",
      "Epoch 9/10\n",
      "11993/11993 [==============================] - 165s 14ms/step - loss: 0.0187 - mae: 0.0964 - val_loss: 0.0191 - val_mae: 0.0989\n",
      "Epoch 10/10\n",
      "11993/11993 [==============================] - 165s 14ms/step - loss: 0.0187 - mae: 0.0963 - val_loss: 0.0191 - val_mae: 0.0986\n"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "hp=kt.HyperParameters()\n",
    "model=build_model(hp)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_split=0.1, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2259/2259 [==============================] - 15s 7ms/step - loss: 0.0153 - mae: 0.0851\n",
      "MSE: 0.015331553295254707\n",
      "MAE: 0.08507969975471497\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(\"MSE:\", test_loss)\n",
    "print(\"MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至 lstm_model.h5\n"
     ]
    }
   ],
   "source": [
    "model.save('lstm_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
